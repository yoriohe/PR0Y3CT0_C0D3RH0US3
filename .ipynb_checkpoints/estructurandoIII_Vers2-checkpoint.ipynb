{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a745d83",
   "metadata": {},
   "source": [
    "# RETENCION CLIENTES EMPRESA DE TELEFONIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db4f0",
   "metadata": {},
   "source": [
    "# Abstract: \n",
    "\n",
    "La fuga de clientes, es comunmente conocida como \"churn\",en una Empresa de Telecomunicaciones.Es un desafío crítico que enfrentan las empresas de telecomunicaciones en la actualidad. \n",
    "La pérdida de clientes puede tener un impacto significativo en los ingresos y la rentabilidad de una empresa, \n",
    "por lo que entender los factores que contribuyen a la fuga de clientes es esencial para su supervivencia en un ambiente de suma competenciacomo es el de las telecomunicaciones.\n",
    " \n",
    "# Contexto Comercial\n",
    "\n",
    "El objetivo general es proporcionar una solución completa de inteligencia de clientes, \n",
    "que ayude a una empresa a anticipar y reducir la pérdida de clientes, conocer la siguiente \n",
    "mejor oferta y mejorar la experiencia para el cliente a través de múltiples canales. \n",
    "\n",
    "# Problema Comercial\n",
    "\n",
    "El objetivo principal de este análisis es proporcionar insights valiosos que ayuden a la empresa a retener a sus\n",
    "clientes y reducir la tasa de Renuncia.\n",
    "Intentaremos  responder a algunas preguntas :\n",
    "¿Cuál es la tasa actual de renuncia de clientes en la empresa de telecomunicaciones?\n",
    "¿Cuál es la distribución de la edad de los clientes?\n",
    "¿Cómo se distribuyen los servicios contratados entre los clientes?\n",
    "¿Cuál es la distribución de los cargos mensuales y totales de los clientes?\n",
    "¿Qué porcentaje de clientes se encuentra satisfecho según las revisiones o encuestas?\n",
    "¿Existe una relación entre la duración del contrato y la tasa de renuncia?\n",
    "¿Cómo se relaciona la edad con la probabilidad de renuncia?\n",
    "¿Los cargos mensuales varían según el tipo de servicio contratado?\n",
    "¿Las revisiones de satisfacción están relacionadas con los servicios contratados?\n",
    "¿Cómo interactúan la duración del contrato, los cargos mensuales y la satisfacción del cliente para influir en la renuncia?\n",
    "¿Existen segmentos de clientes específicos con patrones de renuncia particulares basados en múltiples variables?\n",
    "¿Cuál es la combinación óptima de servicios contratados que se asocia con la menor tasa de renuncia?\n",
    "\n",
    "#  Hipótesis General:\n",
    "\n",
    "\"La tasa de renuncia de clientes en la empresa de telecomunicaciones está influenciada por una combinación de factores demográficos, patrones de consumo de servicios y niveles de satisfacción del cliente. A través del análisis de datos, buscamos identificar las variables clave que tienen un impacto significativo en la tasa de renuncia y proporcionar recomendaciones para reducir la renuncia de clientes y mejorar la retención.\"\n",
    "\n",
    "# Contexto Analítico :\n",
    "\n",
    "\n",
    "Contenido del Archivo de datos: Contiene 7043 filas (clientes) y 21 columnas (características). La columna \"Churn\" es nuestro variable target. Cada fila representa un cliente, cada columna contiene los atributos del cliente descritos en la columna Metadatos.\n",
    "\n",
    "El conjunto de datos incluye información sobre: Clientes que se fueron en el último mes. Columna Churn (Renuncia) Servicios a los que se ha suscrito cada cliente: phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies. Información de la cuenta del cliente: cuánto tiempo ha sido cliente, contrato, método de pago, facturación electrónica, cargos mensuales y cargos totales. Información demográfica sobre los clientes: sexo, rango de edad y si tienen socios y dependientes Fuente\n",
    "\n",
    "ATRIBUTOS:\n",
    "\n",
    "customerID: Customer ID\n",
    "\n",
    "gender : Si el cliente es hombre o mujer.\n",
    "\n",
    "SeniorCitizen : Si el cliente es persona mayor o no (1, 0)\n",
    "\n",
    "Partner: Si el cliente tiene pareja o no (Sí, No)\n",
    "\n",
    "Dependents: Si el cliente tiene dependientes o no (Sí, No)\n",
    "\n",
    "Tenure : (Tenencia) Número de meses que el cliente ha permanecido en la empresa.\n",
    "\n",
    "PhoneService :Si el cliente tiene servicio telefónico o no (Sí, No)\n",
    "\n",
    "MultipleLines: Si el cliente tiene varias líneas o no (Sí, No, No hay servicio telefónico)\n",
    "\n",
    "InternetService : Proveedor de servicios de internet del cliente (DSL, Fibra óptica, No)\n",
    "\n",
    "OnlineSecurity: Si el cliente tiene seguridad en línea o no (Sí, No, No servicio de internet)\n",
    "\n",
    "OnlineBackup: Si el cliente tiene respaldo en línea o no (Sí, No, No hay servicio de Internet)\n",
    "\n",
    "DeviceProtection: Si el cliente tiene protección del dispositivo o no (Sí, No, Sin servicio de Internet)\n",
    "\n",
    "TechSupport: Si el cliente tiene soporte técnico o no (Sí, No, No servicio de internet)\n",
    "\n",
    "StreamingTV: Si el cliente tiene streaming de TV o no (Sí, No, No servicio de internet)\n",
    "\n",
    "StreamingMovies: Si el cliente tiene streaming de películas o no (Sí, No, No servicio de internet)\n",
    "\n",
    "Contract: El plazo del contrato del cliente (mes a mes, un año, dos años)\n",
    "\n",
    "PaperlessBilling: Si el cliente dispone de facturación electrónica o no (Sí, No)\n",
    "\n",
    "PaymentMethod: El método de pago del cliente (cheque electrónico, cheque enviado por correo, transferencia bancaria (automática), tarjeta de crédito (automática))\n",
    "\n",
    "MonthlyCharges:El importe cobrado a la cliente mensualmente.\n",
    "\n",
    "TotalCharges: El importe total cargado a la cliente.\n",
    "\n",
    "Churn: Si la cliente Canceló su suscripción o no (Sí o No)\n",
    "Comenzaremos a responder las preguntas realizadas anteriormente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03139d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos  Libreras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns # Entendiendo mis variables\n",
    "import pprint\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e58c744",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cargo Datasets y Verificamos su consistencia:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/yoriohe/ProyectoCoderHouse/main/WA_Fn-UseC_-Telco-Customer-Churn-Base.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m df\u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mread_csv(url,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    713\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    717\u001b[0m     path_or_buf,\n\u001b[0;32m    718\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    719\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    720\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    721\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    725\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    367\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    369\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:270\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Cargo Datasets y Verificamos su consistencia:\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/yoriohe/ProyectoCoderHouse/main/WA_Fn-UseC_-Telco-Customer-Churn-Base.csv'\n",
    "\n",
    "df=  pd.read_csv(url,sep=\",\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f8214",
   "metadata": {},
   "source": [
    "# Variable Target: Churn\n",
    "La variable objetivo es de tipo **Categorica**, por lo que el modelo a desarrollar será de tipo **Aprendizaje Supervisado: Regresión Logística**. \n",
    "<br> <br/>\n",
    "A continuación se presentarán algunas estadísticas para entender el comportamiento, formato y distribución de esta variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb984e",
   "metadata": {},
   "source": [
    "# Feature selection: Filter Feature Selection \n",
    "## Correlación con el Target\n",
    "Se calcula el coeficiente de correlación de los Features con el target y se ordena de mayor a menor valor absoluto. \n",
    "        <br>\n",
    "**Aclaración:** Sólo sirve para features **numéricas**, así que en caso de ser categóricas combiene realizar alguna transformación. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbb5ef",
   "metadata": {},
   "source": [
    "## ¿Cómo transformo categorías a números? \n",
    "Algunos métodos: \n",
    "1. **One-Hot (One-Hot Encoding):** Crea una columna binaria para cada categoría en la variable original. \n",
    "<br>\n",
    "Tener cuidado cuando la variable tiene demasiadas categorías posibles porque se pueden generar muchas features. \n",
    "2. **Target Encoding:** A cada categoría se asigna une mátrica que tiene relación con el target (ejemplo, promedio, mediana). <br>Tener cuidado si hay categorías con muy pocos registros ya que las métricas pueden ser no representativas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que Tipos de Datos son:\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b831db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto la columna de TotalCharges de Tipo Object a float\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f750ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La columna de Senior Citizen, la transformamos en SI o NO\n",
    "cod_Jubilado = {0:'No', 1: 'Si'}\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].map(cod_Jubilado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0be0c",
   "metadata": {},
   "source": [
    "## Identifiquemos qué variables categóricas tenemos que trabajar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d1d88",
   "metadata": {},
   "source": [
    "# One-Hot Encoding\n",
    "Generaremos variables binarias para las categorías de las variables categóricas con 5 valores distintos o menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categoricas = df.select_dtypes(include=['object'])\n",
    "features_categoricas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c95079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuántos valores distintos tiene cada categoría?\n",
    "valores_distintos = features_categoricas.nunique()\n",
    "print(valores_distintos.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero las selecciono\n",
    "col_aTransformar = valores_distintos.index[valores_distintos<=5]\n",
    "col_aTransformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fcbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patra transformarlas, vamos a usar el método get_dummies de pandas: \n",
    "df_dummies = pd.get_dummies(df[col_aTransformar],drop_first=True)\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ed601",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape,df_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junto los resultados \n",
    "df = pd.concat([df, df_dummies], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b95c7a",
   "metadata": {},
   "source": [
    "# Target Encoding \n",
    "Las variables con más de 5 valores posibles les haremos un tratamiento de Target Encoding, pero de manera más personalizada, para asegurarnos que haya cantidad suficiente de registros para calcular promedios o medianas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2caa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb15c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bf72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto la columna de TotalCharges de Tipo Object a float\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca42837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La columna de Senior Citizen, la transformamos en SI o NO\n",
    "cod_Jubilado = {0:'No', 1: 'Si'}\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].map(cod_Jubilado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la columna Modificada\n",
    "print(df['SeniorCitizen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a217668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeo que no haya ningún duplicado en la columna de \"customerID\"\n",
    "boolean = df.duplicated(subset=['customerID']).any()\n",
    "print(boolean, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28834e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d508ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenar los valores faltantes en TotalCharges con MonthlyCharges\n",
    "df['TotalCharges'].fillna(df['MonthlyCharges'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd861387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeo nuevamente si existen valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b86eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2965ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuál es la tasa actual de renuncia de clientes en la empresa de telecomunicaciones (ESTA SERA NUESTRA VARIABLE TARGET)?\n",
    "clientes_renunciados = df[df['Churn'] == \"Yes\"].shape[0]\n",
    "total_clientes = df.shape[0]\n",
    "print(f\"Cantidad de Clientes Activos en el mes {total_clientes}\")\n",
    "print(f\"Cantidad de clientes que renunciaron: {clientes_renunciados}\")\n",
    "tasa_renuncia = (clientes_renunciados / total_clientes) * 100\n",
    "print(f\"Tasa de renuncia del mes {round(tasa_renuncia,1)} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos a visualizar la información de nuestro interés.\n",
    "# Creamos  el primer gráfico de barras (Clientes Totales vs. Churn (RENUNCIAS))\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot 1: Cantidad de Clientes Totales vs. Cantidad de Clientes que se han Ido\n",
    "plt.subplot(1, 2, 1)\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "bars = plt.bar(churn_counts.index, churn_counts.values, color=['green', 'red'])\n",
    "plt.xlabel('Renuncia')\n",
    "plt.ylabel('Cantidad de Clientes')\n",
    "plt.title('Cantidad de Clientes Totales vs. Cantidad de Clientes que se han Ido')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height}',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3), textcoords='offset points',\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(churn_counts.index, ['No', 'Sí'])\n",
    "\n",
    "# Subplot 2: Tasa de Renuncia de Clientes\n",
    "plt.subplot(1, 2, 2)\n",
    "tasa_renuncia = (clientes_renunciados / total_clientes)*100\n",
    "\n",
    "etiquetas = ['Renunciaron', 'No Renunciaron']\n",
    "porcentajes = [tasa_renuncia, 100 - tasa_renuncia]\n",
    "colores = ['red', 'GREEN']\n",
    "\n",
    "plt.bar(etiquetas, porcentajes, color=colores)\n",
    "for i, porcentaje in enumerate(porcentajes):\n",
    "    plt.text(i, porcentaje + 1, f'{porcentaje:.1f}%', ha='center')\n",
    "\n",
    "plt.title('Tasa de Renuncia de Clientes')\n",
    "plt.ylabel('Porcentaje (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Ajustar el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar los subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56eed85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Verificamos como se distribuyen los principales atributos\n",
    "# Por atributo principal verificamos: \n",
    "#1- En el caso de Sexo, Existen una paridad de Clientes de ambos sexos.\n",
    "#2- Existe un 16% de Clientes Pasivos del Total de Clientes.\n",
    "#3- Los que tienen pareja el 48% del total.\n",
    "#4 - El 70% de Clientes no tienen grupo familiar.\n",
    "\n",
    "# Configurar la cuadrícula de subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Gráfico de barras para \"gender\"\n",
    "sns.countplot(x=\"gender\", data=df, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Distribución de género\")\n",
    "\n",
    "# Gráfico de barras para \"SeniorCitizen\"\n",
    "sns.countplot(x=\"SeniorCitizen\", data=df, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Distribución de personas mayores\")\n",
    "axes[0, 1].set_xticks([0, 1])\n",
    "axes[0, 1].set_xticklabels([\"No\", \"Sí\"])\n",
    "\n",
    "# Gráfico de barras para \"Partner\"\n",
    "sns.countplot(x=\"Partner\", data=df, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Distribución de parejas\")\n",
    "\n",
    "# Gráfico de barras para \"Dependents\"\n",
    "sns.countplot(x=\"Dependents\", data=df, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Distribución de dependientes\")\n",
    "\n",
    "# Agregar valores y pesos relativos en cada subplot\n",
    "for ax in axes.flat:\n",
    "    total_count = len(df)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height}\\n({(height/total_count*100):.2f}%)',\n",
    "                    xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                    xytext=(0, 5),  # 5 puntos de desplazamiento vertical\n",
    "                    textcoords='offset points',\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Ajustar el diseño general\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59868a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELACIONO ESTOS ATRIBUTOS CON LA VARIABLE TARGET CHURN (RENUNCIA)\n",
    "# **INSIGHTS**: \n",
    "#1- En el caso de Sexo, no se ve un comportamiento determinante por sexo ( Cantidad de renunicias son similares).\n",
    "#2- Cuando realiza,por Activos se verifica mayor renuncia que los pasivos\n",
    "#3- Los que NO tienen pareja son los que en este mes mas renuncian \n",
    "#4 - Los que no tienen grupo familiar  son los que mayor renuncian\n",
    "\n",
    "# Configurar la cuadrícula de subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Crear gráficos de barras apilados para \"gender\" en función de \"Churn\"\n",
    "sns.countplot(x=\"gender\", hue=\"Churn\", data=df, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Distribución de género por Renuncia\")\n",
    "\n",
    "# Crear gráficos de barras apilados para \"SeniorCitizen\" en función de \"Churn\"\n",
    "sns.countplot(x=\"SeniorCitizen\", hue=\"Churn\", data=df, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Distribución de personas mayores por Renuncia\")\n",
    "axes[0, 1].set_xticks([0, 1])\n",
    "axes[0, 1].set_xticklabels([\"No\", \"Sí\"])\n",
    "\n",
    "# Crear gráficos de barras apilados para \"Partner\" en función de \"Churn\"\n",
    "sns.countplot(x=\"Partner\", hue=\"Churn\", data=df, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Distribución de parejas por Renuncia\")\n",
    "\n",
    "# Crear gráficos de barras apilados para \"Dependents\" en función de \"Churn\"\n",
    "sns.countplot(x=\"Dependents\", hue=\"Churn\", data=df, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Distribución de dependientes por Renuncia\")\n",
    "\n",
    "# Agregar valores y pesos relativos en cada subplot\n",
    "for ax in axes.flat:\n",
    "    total_count = len(df)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height}\\n({(height/total_count*100):.2f}%)',\n",
    "                    xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                    xytext=(0, 5),  # 5 puntos de desplazamiento vertical\n",
    "                    textcoords='offset points',\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Ajustar el diseño general\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un Histograma utilizando Seaborn para verificar la distribución de la variable TERNURE (ANTIGUEDAD).\n",
    "ax = sns.histplot(df['tenure'], bins=int(180/5), color='darkblue',\n",
    "                  edgecolor='black', kde=False, linewidth=4)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('# of Customers')\n",
    "ax.set_xlabel('Tenure (Meses)')\n",
    "ax.set_title('# de clientes por  Ternure(Atniguedad) (en meses)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "#1. Tenure: Después de observar el Histograma que sigue, podemos observar\n",
    "# una buena cantidad de clientes que permanecen con solo un mes en la empresa\n",
    "# mientras tambien hay  muchos de los clientes que tienen 72 meses. \n",
    "# INSIGHT : esto puede ser potencialemnte porque tienen distintos tipos de servicios  prestados\n",
    "# que , basasdos en el que cada uno tiene,puede ser mas facil o mas dificil irse de la empresa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff71da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veo la relación entre antiguedad y precio total y Existe una clara correlación entre los mismos\n",
    "\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df con columnas \"antigüedad(tenure)\" y \"precio_total(Total Charges)\"\n",
    "sns.scatterplot(x='tenure', y='TotalCharges', data=df)\n",
    "\n",
    "# Puedes personalizar el gráfico agregando etiquetas y un título\n",
    "plt.xlabel('Antigüedad')\n",
    "plt.ylabel('Precio Total')\n",
    "plt.title('Relación entre Antigüedad y Precio Total')\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizo la relación de tipo de contrato con la Renuncia(Churn). \n",
    "\n",
    "\n",
    "# Crear un gráfico de barras apiladas para el tipo de contrato en función de Churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Contract', hue='Churn', palette='Set1')\n",
    "plt.xlabel('Tipo de Contrato')\n",
    "plt.ylabel('Cantidad de Clientes')\n",
    "plt.title('Distribución de Tipo de Contrato por Churn')\n",
    "plt.xticks(rotation=45)  # Rotar etiquetas del eje X para mayor claridad\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d0051",
   "metadata": {},
   "source": [
    "Se ve claramente que los contratos mensuales son los que generan mayor cantidad de renuncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos las cantidades por tipo de contrato actual.\n",
    "df.Contract.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d0802",
   "metadata": {},
   "source": [
    "La mayor cantidad de Clientes con pagos electrinicos  son los que renucian\n",
    "El Pago por Transferencia, por cheques y débito automático son los que los que menos renuncian \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dabb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame para contar la cantidad de servicios\n",
    "services_df = df[['PhoneService', 'InternetService']].copy()\n",
    "\n",
    "# Contar la cantidad de cada combinación de servicios\n",
    "service_counts = services_df.groupby(['PhoneService', 'InternetService']).size().reset_index(name='Count')\n",
    "\n",
    "# Calcular el porcentaje relativo\n",
    "service_counts['Relative Percentage'] = (\n",
    "    service_counts['Count'] / service_counts['Count'].sum() * 100\n",
    ")\n",
    "\n",
    "# Configuración del estilo de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Crear un gráfico de barras utilizando seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='PhoneService', y='Count', hue='InternetService', data=service_counts, palette='viridis'\n",
    ")\n",
    "\n",
    "# Añadir etiquetas con los números y porcentajes encima de las barras\n",
    "for p in barplot.patches:\n",
    "    height = p.get_height()\n",
    "    barplot.annotate(f'{height:.0f} ({height / service_counts[\"Count\"].sum() * 100:.1f}%)',\n",
    "                     (p.get_x() + p.get_width() / 2., height),\n",
    "                     ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Phone Service')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Número de clientes con Teléfono y Servicio de Internet')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce08ce7",
   "metadata": {},
   "source": [
    "INSIGHTS: \n",
    "- DEL TOTAL DE CLIENTES SOLO EL 9,7% NO TIENE SERVICIOS DE TELEFONIA (682 CLIENTES) Y  EL 21,7% NO TIENEN\n",
    "INTERNET (1526)\n",
    "- EL SERVICIO DE INTERNET  MAS UTILIZADO ES DSL UTILIZADO POR EL 44% (3096 CLIENTES), SEGUIDO DSL CON EL 24,7% (1739 CLIENTES)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13626d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec947b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo columna para ver quienes tienen internet + telefono.\n",
    "df[\"pack\"]= df[\"PhoneService\"] + df[\"InternetService\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa608266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco ver cuantos servicios de internet tiene cada cliente. Creo columna.\n",
    "\n",
    "df[\"Cant_Internet\"]= df[\"InternetService\"]+ df[\"OnlineSecurity\"] + df[\"OnlineBackup\"]+ df[\"DeviceProtection\"]+ df[\"TechSupport\"]+ df[\"StreamingTV\"]+df[\"StreamingMovies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a0431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histograma de cantidad de clientes que tome 1 o mas servicios de internet por Servicios de internet\n",
    "sns.histplot(data=df, x='Cant_Internet', bins=10, kde=True)  # Puedes ajustar el número de bins según tus preferencias\n",
    "\n",
    "# Personalizar el gráfico con etiquetas y título\n",
    "plt.xlabel('Cantidad de Servicios de Internet por Cliente')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Cantidad de Servicios de Internet por Cliente')\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653edb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "service_columns = ['PhoneService', 'MultipleLines', 'InternetService', \n",
    "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                   'TechSupport', 'StreamingTV', 'StreamingMovies', 'Churn']\n",
    "service_data = df[service_columns]\n",
    "\n",
    "# Transforma las variables categóricas a variables dummy\n",
    "service_data = pd.get_dummies(service_data, columns=['PhoneService', 'MultipleLines', 'InternetService', \n",
    "                                                     'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                                                     'TechSupport', 'StreamingTV', 'StreamingMovies'], drop_first=True)\n",
    "\n",
    "# Configuración del estilo de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Crear un gráfico de barras apiladas para la distribución de servicios por churn\n",
    "plt.figure(figsize=(12, 8))\n",
    "service_data.groupby('Churn').sum().transpose().plot(kind='bar', stacked=True, colormap='coolwarm')\n",
    "plt.title('Distribución de Servicios por Churn')\n",
    "plt.xlabel('Servicio')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.legend(title='Churn', loc='upper right', labels=['No Churn', 'Churn'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73618c23",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Analizo relación entre Tenure(Antiguedad como cliente) y Churn(Renuncia). \n",
    "# Boxplot de la relación entre Tenure y Churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Churn', y='tenure', data=df)\n",
    "plt.title('Relación entre Antigüedad como cliente y Renuncia')\n",
    "plt.xlabel('Renuncia (Churn)')\n",
    "plt.ylabel('Antigüedad como cliente (Tenure)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635c3c2",
   "metadata": {},
   "source": [
    " Analizo relación entre Tenure y Churn. Claramente observamos que los que se han ido tenían menos tiempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Selecciona solo las columnas numéricas para la matriz de correlación\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Configura el tamaño de la figura\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Crea el mapa de calor con Seaborn\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "\n",
    "# Añade el título\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5a115",
   "metadata": {},
   "source": [
    "# FEATURES SELECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41974458",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/yoriohe/ProyectoCoderHouse/main/WA_Fn-UseC_-Telco-Customer-Churn-Base.csv'\n",
    "\n",
    "dff=  pd.read_csv(url,sep=\",\")\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"gender\"].replace({\"Female\" : 0,  \"Male\": 1}, inplace=True)\n",
    "dff[\"SeniorCitizen\"].replace({\"Yes\" : 1,  \"No\": 0}, inplace=True)\n",
    "dff[\"Partner\"].replace({\"Yes\" : 1,  \"No\": 0}, inplace=True)\n",
    "dff[\"Dependents\"].replace({\"Yes\" : 1,  \"No\": 0}, inplace=True)\n",
    "dff[\"PhoneService\"].replace({\"Yes\" : 1,  \"No\": 0}, inplace=True)\n",
    "dff[\"MultipleLines\"].replace({\"Yes\" : 1,  \"No\": 0, \"No phone service\": 0}, inplace=True)\n",
    "dff[\"InternetService\"].replace({\"Fiber optic\": 1, \"DSL\": 1, \"DLS\": 1, \"Fiber_optic\":1, \"No\": 0, \"_\": 0}, inplace=True)\n",
    "dff[\"OnlineSecurity\"].replace({'No internet service': 0, \"No\": 0, \"Yes\": 1}, inplace= True)\n",
    "dff[\"OnlineBackup\"].replace({'No internet service': 0, \"No\": 0, \"Yes\": 1}, inplace= True)\n",
    "dff[\"DeviceProtection\"].replace({'No internet service': 0, \"No\": 0, \"Yes\": 1}, inplace= True)\n",
    "dff[\"TechSupport\"].replace({'No internet service': 0, \"No\": 0, \"Yes\": 1}, inplace= True)\n",
    "dff[\"StreamingTV\"].replace({'No internet service': 0, \"No\": 0, \"Yes\": 1}, inplace= True)\n",
    "dff[\"StreamingMovies\"].replace({'No internet service': 0, \"No\": 0, \"Yes\": 1}, inplace= True)\n",
    "dff[\"Contract\"].replace({\"Month-to-month\": 1, \"One year\": 0, \"Two year\": 0}, inplace=True)\n",
    "dff[\"PaperlessBilling\"].replace({\"Yes\" : 1,  \"No\": 0}, inplace=True)\n",
    "dff[\"PaymentMethod\"].replace({\"Electronic check\": 1, \"Mailed check\": 0, \"Credit card (automatic)\": 0, \"Bank transfer (automatic)\": 0}, inplace=True)\n",
    "dff[\"Churn\"].replace({\"Yes\" : 1,  \"No\": 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizar la variable 'tenure' en intervalos\n",
    "#dff['tenure_group'] = pd.cut(dff['tenure'], bins=[0, 12, 24, 36, 48, 60, np.inf], labels=['0-12', '13-24', '25-36', '37-48', '49-60', '60+'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ver, qué construí? \n",
    "#dff.groupby('tenure_group').agg(      \n",
    "#    MINIMO = ('Churn', 'min'),\n",
    "#    MAXIMO = ('Churn', 'max'),\n",
    "#    Cantidad = ('Churn','count')\n",
    "#).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tenure_group es de tipo 'category'\n",
    "# Si no lo es, primero conviértelo a categoría usando: df['tenure_group'] = df['tenure_group'].astype('category')\n",
    "\n",
    "# Asigna valores numéricos a las categorías\n",
    "'''\n",
    "tenure_group_mapping = {\n",
    "    '0-12 months': 1,\n",
    "    '13-24 months': 2,\n",
    "    '25-36 months': 3,\n",
    "    '37-48 months': 4,\n",
    "    '49-60 months': 5,\n",
    "    '61+ months': 6\n",
    "}\n",
    "\n",
    "dff['tenure_group'] = dff['tenure_group'].map(tenure_group_mapping)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo columna para ver quienes tienen internet + telefono.\n",
    "dff[\"pack\"]= dff[\"PhoneService\"] + dff[\"InternetService\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco ver cuantos servicios de internet tiene cada cliente. Creo columna.\n",
    "\n",
    "dff[\"Cant_Internet\"]= dff[\"InternetService\"]+ dff[\"OnlineSecurity\"] + dff[\"OnlineBackup\"]+ dff[\"DeviceProtection\"]+ dff[\"TechSupport\"]+ dff[\"StreamingTV\"]+dff[\"StreamingMovies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7766754",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de85909",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Elimina las columnas no numéricas antes de calcular la correlación\n",
    "df_numeric = dff.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calcula la matriz de correlación\n",
    "matriz_correlacion = df_numeric.corr(method='pearson')\n",
    "\n",
    "# Selecciona la variable target para estudiar únicamente correlación con ella \n",
    "matriz_correlacion_target = matriz_correlacion['Churn'].abs()\n",
    "\n",
    "# Excluye columnas específicas del análisis de correlación\n",
    "columnas_a_excluir = ['Churn']\n",
    "matriz_correlacion_target = matriz_correlacion_target.drop(columns=columnas_a_excluir, index=columnas_a_excluir)\n",
    "\n",
    "# Ordena de mayor a menor correlación \n",
    "matriz_correlacion_target = matriz_correlacion_target.sort_values(ascending=False)\n",
    "\n",
    "# Muestra la matriz de correlación\n",
    "print(matriz_correlacion_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabde7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configura el tamaño de la figura\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Crea un gráfico de barras horizontales\n",
    "sns.barplot(x=matriz_correlacion_target, y=matriz_correlacion_target.index, palette=\"viridis\")\n",
    "\n",
    "# Añade etiquetas y título\n",
    "plt.xlabel('Correlación Absoluta')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Correlación de Variables con Churn')\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1467f15",
   "metadata": {},
   "source": [
    "# Wrapper Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157bd56e",
   "metadata": {},
   "source": [
    "1) Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30faa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_nulos  = dff.isnull().sum()\n",
    "columnas_con_nulos = valores_nulos[valores_nulos == 0]\n",
    "columnas_con_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino función para hacer la selección de varaibles\n",
    "import statsmodels.api as sm\n",
    "def forward_selection(data, target, significance_level):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(dtype = 'float64',\n",
    "                             index = remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0070d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Features\n",
    "X = dff[['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'Contract',\n",
    "        'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'pack', 'Cant_Internet']]\n",
    "\n",
    "# Target\n",
    "y = dff['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35be727",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff98f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['SeniorCitizen'] = pd.to_numeric(X['SeniorCitizen'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140eb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['SeniorCitizen'] = pd.to_numeric(X['SeniorCitizen'], errors='coerce')\n",
    "print(X.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['SeniorCitizen' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f737a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES_ELEGIDAS = forward_selection(data = X,\n",
    "                                       target = y,\n",
    "                                       significance_level = 0.01)\n",
    "print(\"Quedaron seleccionadas:\")\n",
    "VARIABLES_ELEGIDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65216a",
   "metadata": {},
   "source": [
    "We will give k = 5 to show case scores of all features.If we want top 3 features we can directly give k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab3751",
   "metadata": {},
   "source": [
    " Using Pearsons coorelation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80ba6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a887e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a4c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc85a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd963b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2cdff60",
   "metadata": {},
   "source": [
    "Actualmente tenemos 20 featuress. Repasemos las 17 características principales y  vemos  cómo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d52395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=5,min_samples_split=100)\n",
    "sfs = SequentialFeatureSelector(model,n_features_to_select=17,scoring='roc_auc',direction='forward')\n",
    "sfs.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "idxes = sfs.get_support(indices=True)\n",
    "top_feats = x_train.columns[idxes]\n",
    "print(f'Las  features seleccionadas son  {top_feats}')\n",
    "\n",
    "\n",
    "### modelo\n",
    "best_est = DecisionTreeClassifier(max_depth=5,min_samples_split=100)\n",
    "best_est = best_est.fit(x_train[top_feats],y_train)\n",
    "train_fpr, train_tpr, thresholds = roc_curve(y_train, best_est.predict_proba(x_train[top_feats])[:,1])\n",
    "test_fpr, test_tpr, thresholds = roc_curve(y_test, best_est.predict_proba(x_test[top_feats])[:,1])\n",
    "\n",
    "\n",
    "print(f'Resultados después de reducir de 20 a 17 features')\n",
    "print('Area  train roc {}'.format(auc(train_fpr, train_tpr)))\n",
    "print('Area  test roc {}'.format(auc(test_fpr, test_tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968c10a",
   "metadata": {},
   "source": [
    "En el conjunto de entrenamiento (train), el AUC es aproximadamente 0.849.\n",
    "En el conjunto de prueba (test), el AUC es aproximadamente 0.814.\n",
    "Con un AUC razonablemente alto tanto en el conjunto de entrenamiento como en el conjunto de prueba. La reducción de características puede ser útil para simplificar y acelerar el modelo sin sacrificar significativamente el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5f8b9",
   "metadata": {},
   "source": [
    "I will try to model the customers who will leave the company (aka Churn) based on the above dataset. I will build the following models:\n",
    "* logistic regression\n",
    "* svm\n",
    "* knn\n",
    "* NaiveBayes\n",
    "* random forest\n",
    "* xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93dd34b",
   "metadata": {},
   "source": [
    "Preparation before model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3524483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3970f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = df.columns.to_list()\n",
    "\n",
    "for elem in [\"customerID\",\"Churn\"]:\n",
    "    train_columns.remove(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52be6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'PhoneService', 'MultipleLines', 'InternetService',\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "       'PaymentMethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the categorical features\n",
    "df_dummies = pd.get_dummies(df[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the numerical features\n",
    "df_dummies[['tenure', 'MonthlyCharges', 'TotalCharges']] = df[['tenure', 'MonthlyCharges', 'TotalCharges']]\n",
    "\n",
    "df_dummies['Churn'] = df['Churn']\n",
    "df_dummies['Churn'] = df_dummies['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "\n",
    "y = df_dummies['Churn']\n",
    "X = df[train_columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in train_columns:\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[col].to_list())\n",
    "    X[col] = le.transform(X[col])\n",
    "\n",
    "\n",
    "clf_stats_df = pd.DataFrame(columns=[\"clf_name\", \"F1-score\", \"auc-score\", \"elapsed_time\"])\n",
    "roc_auc_score_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4898d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60058b",
   "metadata": {},
   "source": [
    "Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38072a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create a 90/10 split of the data \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xtrain, xvalid, ytrain, yvalid \u001b[38;5;241m=\u001b[39m train_test_split(X, y, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, stratify \u001b[38;5;241m=\u001b[39m y)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a 90/10 split of the data \n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.1, stratify = y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "predictions_probas_list = np.zeros([len(yvalid), 2])\n",
    "#predictions_test_xgb = np.zeros(len(test_df))\n",
    "\n",
    "roc_auc_list = []\n",
    "num_of_folds = 10\n",
    "num_fold = 0\n",
    "#feature_importance_df = pd.DataFrame()\n",
    "\n",
    "folds = StratifiedKFold(n_splits=num_of_folds, shuffle=False)\n",
    "\n",
    "for train_index, valid_index in folds.split(xtrain, ytrain):\n",
    "    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n",
    "    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n",
    "\n",
    "    print()\n",
    "    print(\"Stratified Fold:\", num_fold)\n",
    "    num_fold = num_fold + 1\n",
    "    print()\n",
    "\n",
    "    clf_stra_logit = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "    clf_stra_logit.fit(xtrain_stra, ytrain_stra)\n",
    "\n",
    "    #fold_importance_df = pd.DataFrame()\n",
    "    #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n",
    "    #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n",
    "    #fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions = clf_stra_logit.predict(xvalid)\n",
    "    predictions_probas = clf_stra_logit.predict_proba(xvalid)\n",
    "    predictions_probas_list += predictions_probas/num_of_folds\n",
    "    \n",
    "    roc_auc_list.append(roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\"))\n",
    "\n",
    "    #predictions_test_xgb += clf_stra_xgb.predict_proba(test_df[xtrain.columns])[:,1]/num_of_folds\n",
    "    \n",
    "predictions = np.argmax(predictions_probas_list, axis=1)\n",
    "roc_auc_score_list.append(roc_auc_list)\n",
    "\n",
    "print()\n",
    "print(classification_report(yvalid, predictions))\n",
    "\n",
    "print()\n",
    "print(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n",
    "\n",
    "print()\n",
    "print(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "skplt.metrics.plot_roc(yvalid, predictions_probas)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n",
    "\n",
    "#sns.set(rc={'figure.figsize':(12, 38)})\n",
    "#clf_stra_logit.plot_importance(clf_stra_logit, title='Feature importance', xlabel='F score', ylabel='Features')\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "clf_stats_df = clf_stats_df.append({\"clf_name\": \"clf_stra_logit\",\n",
    "                     \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n",
    "                     \"auc-score\": roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"),\n",
    "                     \"elapsed_time\": elapsed_time}, ignore_index=True)\n",
    "\n",
    "print()\n",
    "print(\"elapsed time in seconds: \", elapsed_time)\n",
    "print()\n",
    "import gc\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc76ba7",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "El modelo tiene un buen desempeño en la clasificación general, con un alto valor de accuracy.\n",
    "La precisión y el recall varían entre las clases, con una mayor precisión para la clase 0 y un recall más bajo para la clase 1.\n",
    "El f1-score ponderado proporciona una medida general del rendimiento del modelo.\n",
    "Las métricas de validación cruzada refuerzan la evaluación del modelo en diferentes particiones del conjunto de datos, mostrando una consistencia en su rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Elimina las columnas no numéricas antes de calcular la correlación\n",
    "df_numeric = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calcula la matriz de correlación\n",
    "matriz_correlacion = df_numeric.corr(method='pearson')\n",
    "\n",
    "# Selecciona la variable target para estudiar únicamente correlación con ella \n",
    "matriz_correlacion_target = matriz_correlacion['Churn'].abs()\n",
    "\n",
    "# Excluye columnas específicas del análisis de correlación\n",
    "columnas_a_excluir = ['Churn']\n",
    "matriz_correlacion_target = matriz_correlacion_target.drop(columns=columnas_a_excluir, index=columnas_a_excluir)\n",
    "\n",
    "# Ordena de mayor a menor correlación \n",
    "matriz_correlacion_target = matriz_correlacion_target.sort_values(ascending=False)\n",
    "\n",
    "# Muestra la matriz de correlación\n",
    "print(matriz_correlacion_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71a92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
